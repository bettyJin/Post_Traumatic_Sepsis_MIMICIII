# -*- coding: utf-8 -*-
"""MIMICIII_DataLoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dFlhKKgvRAbWVUCGCKcAQl-P0tP68LYa

# Set Up
"""

# Commented out IPython magic to ensure Python compatibility.
import gzip
import os
import re
import numpy as np
import pandas as pd
from datetime import datetime, time, date, timedelta
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle



# cd to code folder
# %cd /content/drive/MyDrive/Yin_AutoEncoder/mimiciii_code/Project
import mimic_utils as utils
import mimiciii_icu_trauma_patient_cohort as trauma_cohort
# import spesis_assignment_preprocess as spesis_preprocess
import mimiciii_spesis_assignment as spesis_label
import mimiciii_features_vitalsigns as vs_features


## Project Path
#PROJECT_PATH = '/content/drive/MyDrive/Yin_AutoEncoder/mimiciii_code/Project'
## Data Path
## mimic original dataset path
#DATASET_PATH = os.path.join(PROJECT_PATH, '1.4')
#PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess')
#TIDATA_PATH = os.path.join(PROJECT_PATH, 'TiData')
#SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#
#
## environment variables of BigQuery
#PROJECT_ID = 'sepsis-mimic3'  #this need to change according to your project_id in BigQuery
#FEATURES_LIST = ['heartrate', #'sysbp',
#                 'diasbp', 'meanbp', 'resprate', 'tempc', 'fio2']

"""
# assign night-time sample with a label
"""

def load_ti_data(ti_data_path, preprocess_path, sepsis_preprocess_path, dataset_path, project_path, project_id,
                 TRUM_df,
                 ti_type='with_nan', features_li = ['heartrate', 'diasbp', 'meanbp', 'resprate', 'tempc', 'fio2'],
                 onset_day_type='cx'):
  """
  ti_type:
    - 'with_nan': ti can have nan values
    - 'ffil': fill nan value by using forward fill method, and droped the samples that still containd nan value
  onset_day_type
    - 'cx' means use cx timestemp as onset day,
    - 'earlier' means use earlier timestemp between (abx, cx) as onset day
  """
  #This table should contain 1 row per patient (with unique hadm_id)
  trum_hadm_id_df = TRUM_df[['hadm_id']].drop_duplicates() # we only need Hosipital Admission ID
  # Load Sepsis Label
  sepsis_label_path = os.path.join(ti_data_path, 'sepsis_label.csv')
  sepsis_label_df = spesis_label.load_sepsis_label(sepsis_label_path,
                                preprocess_path, sepsis_preprocess_path, dataset_path, project_id,
                                trum_hadm_id_df)
  non_sepsis_ids, sepsis_ids = sepsis_label_df.isSepsis==0, sepsis_label_df.isSepsis==1
  print(f"Trum Cohort: sepsis label(%d) + non sepsis label(%d) = %d"%(sum(sepsis_ids), sum(non_sepsis_ids), sepsis_label_df.shape[0])) # (s:609, non-s:961 = 1570)
  # extract ti data for sepsis patient and merge with onset day
  if onset_day_type=='cx':
    onset_day = sepsis_label_df.loc[sepsis_ids,['hadm_id', 'isSepsis','cx_datetime',	'cx_day']] # we use cx timestemp as onset day
    onset_day.rename({'cx_datetime':'onset_datetime',	'cx_day':'onset_day'}, inplace=True, axis=1)
  elif onset_day_type=='earlier':
    onset_day = sepsis_label_df.loc[sepsis_ids,['hadm_id', 'isSepsis', 'timestemp',	'day']] # we use earlier timestemp between (abx, cx) as onset day
    onset_day.rename({'timestemp':'onset_datetime',	'day':'onset_day'}, inplace=True, axis=1)

  # Load time-series Features
  if ti_type=='forward':
    night_ti = vs_features.load_vs_features(os.path.join(ti_data_path, 'vs_ti_ffil.pkl'),
                                preprocess_path, sepsis_preprocess_path, project_path, project_id,
                                features_li, TRUM_df, filling_method='forward')
    print(f"Ti-data with size %d for %d patients"%(night_ti.shape[0], night_ti.hadm_id.nunique()))
  elif ti_type=='f_and_b':
    night_ti = vs_features.load_vs_features(os.path.join(ti_data_path, 'vs_ti_fbfil.pkl'),
                                preprocess_path, sepsis_preprocess_path, project_path, project_id,
                                features_li, TRUM_df, filling_method='f_and_b')
    print(f"Ti-data with size %d for %d patients"%(night_ti.shape[0], night_ti.hadm_id.nunique()))
  elif ti_type=='with_nan':
    night_ti = vs_features.load_vs_features(os.path.join(ti_data_path, 'vs_ti_w_nan.pkl'),
                                preprocess_path, sepsis_preprocess_path, project_path, project_id,
                                features_li, TRUM_df, filling_method=None)
    print(f"Ti-data with size %d for %d patients"%(night_ti.shape[0], night_ti.hadm_id.nunique()))


  # extract ti data for nonsepsis patient these data are ready
  nonsepsispatient_ti_df = night_ti[night_ti.hadm_id.isin(sepsis_label_df.loc[non_sepsis_ids, 'hadm_id'])]
  nonsepsispatient_ti_df.loc[:, 'label'] = 0 #np.zeros(nonsepsispatient_ti_df.shape[0])
  #
  sepsispatient_ti_df = night_ti[night_ti.hadm_id.isin(onset_day.hadm_id)]
  print(f"Ti-Records:%d = %d(sepsis patient(%d)) + %d(non-sepsis patient(%d))"%(night_ti.shape[0],
      sepsispatient_ti_df.shape[0], sepsispatient_ti_df.hadm_id.nunique(),
      nonsepsispatient_ti_df.shape[0], nonsepsispatient_ti_df.hadm_id.nunique())) # (s:598, non-s:937= 1535)

  sepsispatient_df = sepsispatient_ti_df.merge(onset_day, on='hadm_id')
  # classify the relationshipe between recorded tiem and onset time
  sepsispatient_df['Date_Group'] = pd.to_datetime(sepsispatient_df.Date_Group)+np.timedelta64(6,'h')
  sepsispatient_df['onset_datetime'] = pd.to_datetime(sepsispatient_df.onset_datetime)
  difference_s = (sepsispatient_df.onset_datetime - sepsispatient_df.Date_Group)/ np.timedelta64(1, 's')
  # if record happen before onset tiemstemp label as 0 first
  sepsispatient_df.loc[difference_s>=0, 'label'] = 0
  # if record happen 24h before onset tiemstemp label as 1
  # (if the onset happen at the last minate of the recordes then also label as 1
  # i.e. difference_s = 0, then also label as 1)
  sepsispatient_df.loc[(difference_s>=0) &(difference_s<24*(60*60)), 'label'] = 1
  # if record happen after onset tiemstemp,ignorded and Droped
  print(f"For sepsis pacients %d(0s), %d(1s), %d(nan)"%(sepsispatient_df.label.value_counts()[0], sepsispatient_df.label.value_counts()[1],sepsispatient_df.label.isna().sum()))
  sepsispatient_df_dropna = sepsispatient_df.dropna(subset =['label']) # drop 78 sample
  print("# of sepsis pacients:\t " ,sepsispatient_df_dropna.hadm_id.nunique())

  # append sepsispatient_df and non-sepsispatient
  mimic_data_df = pd.concat([nonsepsispatient_ti_df,
                            sepsispatient_df_dropna[nonsepsispatient_ti_df.columns]])
  # print(f"After assign label, \n\tSepsis patient records(P:%d, N:%d) + Non-Sepsis patient records(P:%d, N:%d)"%(
  #     sepsispatient_df_dropna.hadm_id.nunique(),sepsispatient_df_dropna.shape[0],
  #     nonsepsispatient_ti_df.hadm_id.nunique(),nonsepsispatient_ti_df.shape[0]))
  neg, pos = mimic_data_df.value_counts('label')
  print(f"Final Dataset: %d(0s) + %d(1s) = %d (P=%d)"%(
      neg, pos, mimic_data_df.shape[0],
      mimic_data_df.hadm_id.nunique()))
  # save
  saved_path =os.path.join(ti_data_path, f'ti_label_%s.pkl'%ti_type)
  night_ti.to_pickle(saved_path)
  print("saved the data at", saved_path)

  return mimic_data_df

"""# split function
* the split is on patient's level, to prevent data leaking
1. select test subset:
> assign InstanceID which is based on patient(Hadm_id) and date \
> if a patient is selected in test dataser, then all the ralative InstanceID for that patients should be able to locat in both table (table with nan value & table w/o nan value) for a fair comparsion \
> the stratify split is based on patient

"""

def train_test_patients_stratify_split(data_w_nan, data_fill,
                                       saved_path=None,isReport=True):
  # assign InstanceID for each instance in data with nan value Table
  data_w_nan.reset_index(drop=True,inplace=True)
  data_w_nan.reset_index(names='InstanceID',inplace=True)
  # share InstanceID for data (w/o nan value) Table, according to hadm_id & Day
  data_fill = data_w_nan[['InstanceID', 'hadm_id','Day']].merge(data_fill, on=['hadm_id', 'Day'], how='right')
  # assign same instance id for both table
  data_w_nan_count = data_w_nan.groupby(['hadm_id']).agg({'label':'sum', 'InstanceID':'count'}).reset_index()
  data_w_nan_count_hamd = data_w_nan_count.shape[0]
  data_fill_count = data_fill.groupby(['hadm_id']).agg({'label':'sum', 'InstanceID':'count'}).reset_index()
  data_fill_count_hamd = data_fill_count.shape[0]
  # drop the rows s.r. in data_fill, but not data_w_nan
  # this instance is fully constract by filling windows, none of the are generate by accual night-time value
  print("Drop unqualify datain fill Table"%data_fill.InstanceID.isna().sum())
  data_fill.dropna(subset=['InstanceID'], inplace=True)
  # find the patients s.t. has same amount of instance in both table
  merge_count = data_w_nan_count.merge(data_fill_count, on=['hadm_id', 'label'])

  test_condidate = merge_count[merge_count.InstanceID_x == merge_count.InstanceID_y]#.hadm_id
  print(f"got %d test_condidate(same recordes should in both table))"%test_condidate.shape[0])

  # get patient's ids for test dataset, based on stratify split of sepsis patients or non-sepsis patients
  text_size_nan, text_size_fill = round(data_w_nan_count_hamd * 0.2), round(data_fill_count_hamd * 0.2)
  print("\n\n", text_size_nan, text_size_fill)
  id_train, id_test, label_train, label_test = train_test_split(test_condidate.hadm_id, test_condidate.label,
                                                                random_state=88, test_size=text_size_fill, shuffle=True,
                                                                stratify=test_condidate.label)
  # print(id_train.shape, id_test.shape, )
  # print(id_train.shape[0] / id_test.shape[0], id_train.shape[0] /id_test.shape[0])
  # assign datadet class (trian/test) in dataset
  data_w_nan.loc[data_w_nan.hadm_id.isin(id_test), 'dataset'] = 'test'
  data_fill.loc[data_fill.hadm_id.isin(id_test), 'dataset'] = 'test'
  print(data_w_nan.dataset.notna().sum())
  print(data_fill.dataset.notna().sum())

  data_w_nan.dataset.fillna('train', inplace=True)
  data_fill.dataset.fillna('train', inplace=True)

  if isReport:
    for name, df in {"with Nan": data_w_nan,"w/o Nan": data_fill}.items():
      print("For data table", name, df.shape)
      report_df = pd.DataFrame(columns = ['NumInstance', 'NumPosInstance', 'RatioPosInstance',
                                          'NumPatient',  "NumSepPatient", "RatioSepPatient"],
                              index=['test', 'train'])
      # count for instance level
      test_0,test_1,train_0, train_1 = df.groupby(['dataset', 'label']).size()
      report_df.loc[:, ['NumInstance', 'NumPosInstance','RatioPosInstance']] = [
          [test_0+test_1,test_1,round(test_1/(test_0+test_1),3)],
          [train_0+train_1,train_1, round(train_1/(train_0+train_1),3)]]

      # count for patient level
      test_0,test_1,train_0, train_1 = df.groupby(['dataset', 'hadm_id']).label.sum().reset_index().groupby(['dataset', 'label']).size()
      report_df.loc[:, ['NumPatient',  "NumSepPatient", "RatioSepPatient"]] = [
          [test_0+test_1,test_1,round(test_1/(test_0+test_1),3)],
          [train_0+train_1,train_1, round(train_1/(train_0+train_1),3)]]
      display(report_df)


  # Saved
  data_w_nan.to_pickle(os.path.join(saved_path, 'mimiciii_dataset_w_nan.pkl'))
  data_fill.to_pickle(os.path.join(saved_path, 'mimiciii_dataset_wo_nan.pkl'))
  return data_w_nan, data_fill

#SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#TRUM_df = trauma_cohort.trum_population_ids(
#    DATASET_PATH, PREPROCESS_DATA_PATH, #local path: mimiciii dataset
#    PROJECT_ID,                         #mimiciii dataset: bigquery id
#    vent_type=['MechVent'], vent_threshold=3,
#    is_report=True)
#TRUM_df.rename({"date_count":"MV_day_count"}, axis=1, inplace=3)
#data_w_nan = load_ti_data(TIDATA_PATH, PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH,
#             DATASET_PATH, PROJECT_PATH, PROJECT_ID,
#             TRUM_df,
#             ti_type='with_nan', features_li=FEATURES_LIST, onset_day_type='cx')
#data_fill = load_ti_data(TIDATA_PATH, PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH,
#             DATASET_PATH, PROJECT_PATH, PROJECT_ID,
#             TRUM_df,
#             ti_type='f_and_b', features_li=FEATURES_LIST, onset_day_type='cx')
#data_w_nan, data_fill = train_test_patients_stratify_split(data_w_nan, data_fill, saved_path=os.path.join(TIDATA_PATH, 'mimiciii_dataset'))

def split_data(df):
  if 'val' in df.dataset.unique():
    # print("already have val subset")
    df.loc[df.dataset=='val', 'dataset'] = 'train'

  hadm_id_df = df[df.dataset=='train'].groupby('hadm_id').label.sum().reset_index()
  id_train, id_val, _, _ = train_test_split(hadm_id_df.hadm_id, hadm_id_df.label,
                                            random_state=66, test_size=0.2,
                                            shuffle=True, stratify=hadm_id_df.label)
  # print(id_train.shape, id_val.shape)
  df.loc[df.hadm_id.isin(id_val), 'dataset']= 'val'

  # extract
  train = df.loc[df.dataset=='train']
  val = df.loc[df.dataset=='val']
  test = df.loc[df.dataset=='test']
  print(train.shape, val.shape, test.shape)
  return train, val, test
  #  ((train['Temporal Features'], train['label']),
  #         (val['Temporal Features'], val['label']),
  #         (test['Temporal Features'], test['label']))
#train, val, test = split_data(data_w_nan)
#train, val, test = split_data(data_fill)

"""
    # load data
"""

## load data w/o nanvalue
#file_path = os.path.join(TIDATA_PATH, 'mimiciii_dataset', 'mimiciii_dataset_wo_nan.pkl')
#if os.path.exists(file_path):
#  data_w_nan = pd.read_pickle(file_path)
#  train, val, test = split_data(data_w_nan)
#else:
#  # Select Trauma Population (IDs)
#  SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#  TRUM_df = trauma_cohort.trum_population_ids(
#      DATASET_PATH, PREPROCESS_DATA_PATH, #local path: mimiciii dataset
#      PROJECT_ID,                         #mimiciii dataset: bigquery id
#      vent_type=['MechVent'], vent_threshold=3,
#      is_report=True)
#  TRUM_df.rename({"date_count":"MV_day_count"}, axis=1, inplace=3)
#  data_w_nan = vs_features.load_ti_data(TIDATA_PATH, PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH,
#               DATASET_PATH, PROJECT_PATH, PROJECT_ID,
#               TRUM_df,
#               ti_type='with_nan', features_li=FEATURES_LIST, onset_day_type='cx')
#  data_fill = vs_features.load_ti_data(TIDATA_PATH, PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH,
#               DATASET_PATH, PROJECT_PATH, PROJECT_ID,
#               TRUM_df,
#               ti_type='f_and_b', features_li=FEATURES_LIST, onset_day_type='cx')
#  data_w_nan, data_fill = train_test_patients_stratify_split(data_w_nan, data_fill, saved_path=os.path.join(TIDATA_PATH, 'mimiciii_dataset'))
#  train, val, test = split_data(data_fill)


## Load data with nan
#file_path = os.path.join(TIDATA_PATH, 'mimiciii_dataset', 'mimiciii_dataset_w_nan.pkl')
#if os.path.exists(file_path):
#  data_w_nan = pd.read_pickle(file_path)
#  train, val, test = split_data(data_w_nan)
#else:
#  # Select Trauma Population (IDs)
#  SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#  TRUM_df = trauma_cohort.trum_population_ids(
#      DATASET_PATH, PREPROCESS_DATA_PATH, #local path: mimiciii dataset
#      PROJECT_ID,                         #mimiciii dataset: bigquery id
#      vent_type=['MechVent'], vent_threshold=3,
#      is_report=True)
#  TRUM_df.rename({"date_count":"MV_day_count"}, axis=1, inplace=3)
#  data_w_nan = vs_features.load_ti_data(TIDATA_PATH, PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH,
#               DATASET_PATH, PROJECT_PATH, PROJECT_ID,
#               TRUM_df,
#               ti_type='with_nan', features_li=FEATURES_LIST, onset_day_type='cx')
#  data_fill = vs_features.load_ti_data(TIDATA_PATH, PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH,
#               DATASET_PATH, PROJECT_PATH, PROJECT_ID,
#               TRUM_df,
#               ti_type='f_and_b', features_li=FEATURES_LIST, onset_day_type='cx')
#  data_w_nan, data_fill = train_test_patients_stratify_split(data_w_nan, data_fill, saved_path=os.path.join(TIDATA_PATH, 'mimiciii_dataset'))
#  train, val, test = split_data(data_w_nan)
