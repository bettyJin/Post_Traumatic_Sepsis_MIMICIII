# -*- coding: utf-8 -*-
"""MIMICII_Features_VitalSigns.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SvGSOD8UBZK0XP3j4K-wMftJdVBptdDO

In this notebook, it generate the time-series for vital signs features for each pacients(hadm_ids) in the cohort, which will be used as the features inputs for our model.

features list:
* HEART_RATE
* SYSTOLIC_BLOOD_PRESSURE,
* DIASTOLIC_BLOOD_PRESSURE
* MEAN_ARTIRIAL_PRESSURE,
* RESPIRATORY_RATE
* FEATURE_TEMP
* FIO2


Source files:(mimic-iii/concepts/pivot/) \
1. [pivoted_vital.sql](https://github.com/MIT-LCP/mimic-code/blob/main/mimic-iii/concepts/pivot/pivoted_vital.sql)
2. [pivoted_fio2.sql](https://github.com/MIT-LCP/mimic-code/blob/main/mimic-iii/concepts/pivot/pivoted_fio2.sql)


**Notes**:

This notebook assumes you have access to MIMIC III (v1.4) on Google BigQuery.
> - To get access for MIMIC III(v1.4) follow [link](https://physionet.org/content/mimiciii/1.4/)
> - To set up MIMIC data on Google BigQuery, follow [link](https://mimic.mit.edu/docs/gettingstarted/cloud/bigquery/)
> - To access MIMIC data in Google Colab, check the [link](https://colab.research.google.com/drive/1REu-ofzNzqsTT1cxLHIegPB0nGmwKaM0?usp=sharing#scrollTo=s-MoFA6NkkbZ)

# Set up
"""

# Commented out IPython magic to ensure Python compatibility.
import gzip
import os
import re
import numpy as np
import pandas as pd
from datetime import datetime, time, date, timedelta
from matplotlib import pyplot as plt

# cd to code folder
# %cd /content/drive/MyDrive/Yin_AutoEncoder/mimiciii_code/Project
import mimic_utils as utils
import mimiciii_icu_trauma_patient_cohort as trauma_cohort
# import spesis_assignment_preprocess as spesis_preprocess
import mimiciii_spesis_assignment as spesis_label

## Project Path
#PROJECT_PATH = '/content/drive/MyDrive/Yin_AutoEncoder/mimiciii_code/Project'
## Data Path
## mimic original dataset path
#DATASET_PATH = os.path.join(PROJECT_PATH, '1.4')
#PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess')
#TIDATA_PATH = os.path.join(PROJECT_PATH, 'TiData')
#SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#
## environment variables of BigQuery
#PROJECT_ID = 'sepsis-mimic3'  #this need to change according to your project_id in BigQuery
#FEATURES_LIST = ['heartrate', #'sysbp',
#                 'diasbp', 'meanbp', 'resprate', 'tempc', 'fio2']

"""
# Load Cohort & Extract Features
load vital sign features from pivoted_vital.sql
load fio2 features from pivoted_fio2.sql
data will be load as chartevent:
    each row repsents 1 records for a sepecfict timestemp for a patient
then filter the data in a range of [48h, 14day]
"""

# Extract raw for trauma cohort
def Extract_Trauma_Raw_VitalSigns(trum_ids, preprocess_path, project_id,
                                    features_list = ['heartrate', 'sysbp', 'diasbp', 'meanbp', 'resprate', 'tempc', 'fio2'],
                                    isreport=True):
  """
  By Default
  Extract 7 features raw data from MIMIC iii dataset
    heartrate	sysbp	diasbp	meanbp	resprate	tempc	fio2
  Two more options that not include by default
    spo2, glucose
  """
  # load vrital sign:
  # includes HeartRate, SysBP, DiasBP, MeanBP,RespRate, TempC
  # excludes: SpO2, Glucose
  path = os.path.join(preprocess_path, 'pivoted_vital.csv')
  if os.path.exists(path):
    # load
    vital_df = pd.read_csv(path)#.hadm_id.shape
  else:
    vital_df = utils.vital_signs_sql2df(project_id, saved_path=path)

  # load fiO2:
  path = os.path.join(preprocess_path, 'pivoted_fio2.csv')
  if os.path.exists(path):
    # load
    fio2_df = pd.read_csv(path, index_col=0)#.hadm_id.shape
  else:
    # extract data
    query = """
      SELECT icustay_id, charttime, fio2
      FROM `physionet-data.mimiciii_derived.pivoted_fio2`
      """
    fio2_df = utils.run_query(query, project_id)
    fio2_df.to_csv(path)

  trum_fio2 = trum_ids[['hadm_id', 'icustay_id', 'admittime']].merge(fio2_df, on='icustay_id', how='inner')
  trum_vital_df = trum_ids[['hadm_id', 'icustay_id', 'admittime']].merge(vital_df, on=['hadm_id', 'icustay_id'], how='inner')
  # display(trum_vital_df.hadm_id.nunique())
  raw_ti = trum_vital_df.merge(trum_fio2, on=['hadm_id',	'icustay_id', 'admittime','charttime'], how='outer')
  # display(raw_ti.hadm_id.nunique())
  if isreport:
    print(f"Extract %d FiO2 samples for %d trauma patients"%(trum_fio2.shape[0], trum_fio2.hadm_id.nunique()))
    print(f"Extract %d vital samples for %d trauma patients"%(trum_vital_df.shape[0], trum_vital_df.hadm_id.nunique()))
    print(f"In total: %d samples for %d trauma patients"%(raw_ti.shape[0], raw_ti.hadm_id.nunique()))

  # calculate time
  raw_ti['admittime'] = pd.to_datetime(raw_ti['admittime'])
  raw_ti['charttime'] = pd.to_datetime(raw_ti['charttime'])
  raw_ti['Day'] = (raw_ti.charttime.dt.date-raw_ti.admittime.dt.date).apply(lambda x: x.days) + 1

  # filter out first 48h
  raw_ti = raw_ti[(raw_ti.charttime-raw_ti.admittime) > timedelta(hours=48)]
  print(f"\t(After filter out first 48h:)%d samples for %d trauma patients"%(raw_ti.shape[0], raw_ti.hadm_id.nunique()))
  # filter out after 14 day
  raw_ti = raw_ti[raw_ti.Day<=14]
  print(f"\t(After filter first 14 days:) %d samples for %d trauma patients"%(raw_ti.shape[0], raw_ti.hadm_id.nunique()))
  # Extract for selected features
  raw_ti = raw_ti[['hadm_id', #'icustay_id',
                   'charttime','Day']+features_list]
  # drop nan values
  raw_ti.dropna(subset= features_list, axis = 0, how = 'all', inplace = True)
  print(f"Finally(after drop na), %d samples for %d trauma patients"%(raw_ti.shape[0], raw_ti.hadm_id.nunique()))
  return raw_ti.drop_duplicates()


"""
# Preprocess: time-serices data
1. Filters the data for night-time hours (22:00 to 06:00) and fill the missing timestemp(for regular time-series shape) 
    (option) Fill the misiing value
2. Convert 1D chart record To 2d time-series data with shape (T, F) where T=9
"""
def extract_night_data(df, filling_method=None, ffill_window_size=6,
                       features_list=['heartrate', 'sysbp', 'diasbp', 'meanbp', 'resprate', 'tempc', 'fio2']):
  """
  Filters the DataFrame for night-time hours (22:00 to 06:00),
  (optional)fills NaN values with previous time points for the same person ('hadm_id'),
  groups by ids (patients + time), then aggregates the values into 2D arrays.
  """
  # Extract date & hour
  # datetime_objects = df['charttime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))
  df.loc[:, ['Date']] = df.charttime.dt.date
  # df.loc[:,['CHARTTIME_Time']] = datetime_objects.dt.time
  df.loc[:,['Hour']] = df.charttime.dt.hour

  if filling_method==None: # then extract more data to fill the missing value in next step
    night_df = df[(df['Hour'] >= 22) | (df['Hour'] <= 6)].sort_values(['hadm_id', 'charttime'])
    print(f"Extract night time, %d smaples for %d trauma pacients"%(night_df.shape[0], night_df.hadm_id.nunique()))
    # Unifying data group for over night date
    # converting time at first_day_time_list(22:00 and 23:00)'s date to time at next_day_time_list's date
    night_df.loc[:, 'Date_Group'] = night_df.Date
    night_df.loc[night_df['Hour'].isin(np.arange(22, 24)), 'Date_Group'] = (night_df['Date'] + timedelta(days=1))
    night_df.loc[night_df['Hour'].isin(np.arange(22, 24)), 'Day'] = (night_df['Day'] + 1)
  else:
    # Filter for rows s.t. within ffill_window or night-time (22:00 and 06:00)
    # (i.e. if ffill_window_size=6, then ffill_window is 16:00-21:00)
    windown_s = 22-ffill_window_size
    windown_e = 6 + ffill_window_size
    night_df = df[(df['Hour'] >= windown_s) | (df['Hour'] <= windown_e)].sort_values(['hadm_id', 'charttime']) # with filling windown
    night_df_only_night = df[(df['Hour'] >= 22) | (df['Hour'] <= 6)].sort_values(['hadm_id', 'charttime'])
    print(f"Extract night time, %d smaples for %d trauma pacients"%(night_df_only_night.shape[0], night_df_only_night.hadm_id.nunique()))
    # Unifying data group for over night date
    # converting time at first_day_time_list(22:00 and 23:00)+filling windoewns's date to time at next_day_time_list's date
    night_df.loc[:, 'Date_Group'] = night_df.Date
    night_df.loc[night_df['Hour'].isin(np.arange(22-ffill_window_size, 24)), 'Date_Group'] = (night_df['Date'] + timedelta(days=1))
    night_df.loc[night_df['Hour'].isin(np.arange(22-ffill_window_size, 24)), 'Day'] = (night_df['Day'] + 1)
  

  # aggregate valus in the same hour into 1 value per feature
  night_AggInHour_df = night_df[[
      'hadm_id',# 'icustay_id',
      'Date_Group', 'Day', 'Hour'] # id+ time
      + features_list].groupby(['hadm_id', #'icustay_id',
                                'Date_Group', 'Day','Hour']).mean().reset_index()
  print(f"After agg one Hour with one value, %d smaples for %d trauma pacients"%(night_AggInHour_df.shape[0], night_AggInHour_df.hadm_id.nunique()))

  # # convert time to index in the list. ex. 22:00 to index 0, 6:00 to index 8
  # full_night.loc[:, 'TimeIndex'] = full_night['Hour'].map( {night_time_list[i]: i for i in range(9)})

  # fill missing timestemp in range
  night_time_list = [22, 23] + [i for i in range(7)]
  night_hour = night_AggInHour_df.groupby(['hadm_id', 'Date_Group','Day']).apply(
      lambda x: pd.DataFrame(night_time_list, columns=['Hour'])
      ).reset_index().rename({'level_3': 'TimeIndex'}, axis=1)
  full_night = night_AggInHour_df.merge(night_hour, on=['hadm_id', 'Date_Group', 'Day','Hour'], how='outer').sort_values(['hadm_id', 'Day', 'TimeIndex'])
  print(f"After fill in missing timestemp, %d smaples for %d trauma pacients"%(full_night.shape[0], full_night.hadm_id.nunique()))

  # fill NaN values within each group (same patient & same night)
  if filling_method!=None:
    if (filling_method=='f_and_b'): 
      # Forward Fill NA/NaN values by propagating the last valid observation to next valid
      full_night = full_night.groupby(['hadm_id', 'Date_Group','Day']).apply(lambda group: group.ffill()).reset_index(drop=True)
      full_night = full_night.groupby(['hadm_id', 'Date_Group','Day']).apply(lambda group: group.bfill()).reset_index(drop=True)
      print(f"After(fill: f&b), %d smaples for %d trauma pacients"%(full_night.shape[0], full_night.hadm_id.nunique()))
    if (filling_method=='forward'):
      # Forward Fill NA/NaN values by propagating the last valid observation to next valid
      full_night = full_night.groupby(['hadm_id', 'Date_Group','Day']).apply(lambda group: group.ffill()).reset_index(drop=True)
      print(f"After(ffil), %d smaples for %d trauma pacients"%(full_night.shape[0], full_night.hadm_id.nunique()))

    # drop row that still contains nan values
    full_night.dropna(subset= features_list, axis = 0, how = 'any', inplace = True)
    # Filter for rows between 22:00 and 06:00 (drop data in filling window)
    full_night = full_night[(full_night['Hour'] >= 22) | (full_night['Hour'] <= 6)]
    print(f"After drop na, %d smaples for %d trauma pacients"%(full_night.shape[0], full_night.hadm_id.nunique()))

    # only keep the day that has all 9 timestamp
    night_timestamp_count = full_night.groupby(['hadm_id',	'Date_Group',	'Day'	]).size().reset_index().rename({0:'num'}, axis=1)
    full_night_timestamp = night_timestamp_count.loc[night_timestamp_count.num==9, ['hadm_id',	'Date_Group',	'Day']]
    # print(full_night_timestamp.shape)
    full_night = full_night.merge(full_night_timestamp, on=['hadm_id',	'Date_Group',	'Day'	])
    # display(full_night.groupby(['hadm_id',	'Date_Group',	'Day'	]).size())
    print(f"After drop irregular data(num timestemp<9), %d smaples for %d trauma pacients"%(full_night.shape[0], full_night.hadm_id.nunique()))

  # print(f"Finial night time data, %d smaples for %d trauma pacients"%(full_night.shape[0], full_night.hadm_id.nunique()))
  return full_night
# night_data = extract_night_data(raw_data, filling_method='f_and_b', features_list=FEATURES_LIST)


# OLD VERSIONdef extract_night_data(df, filling_method=None, ffill_window_size=6,
#                        features_list=['heartrate', 'sysbp', 'diasbp', 'meanbp', 'resprate', 'tempc', 'fio2']):
#   """
#   Filters the DataFrame for night-time hours (22:00 to 06:00),
#   (optional)fills NaN values with previous time points for the same person ('hadm_id'),
#   groups by ids (patients + time), then aggregates the values into 2D arrays.
#   """
#   # Extract date & hour
#   # datetime_objects = df['charttime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))
#   df.loc[:, ['Date']] = df.charttime.dt.date
#   # df.loc[:,['CHARTTIME_Time']] = datetime_objects.dt.time
#   df.loc[:,['Hour']] = df.charttime.dt.hour

#   # Filter for rows s.t. within ffill_window or night-time (22:00 and 06:00)
#   # (i.e. if ffill_window_size=6, then ffill_window is 16:00-21:00)
#   windown_s = 22-ffill_window_size
#   night_df = df[(df['Hour'] >= windown_s) | (df['Hour'] <= 6)].sort_values(['hadm_id', 'charttime']) # with filling windown
#   night_df_only_night = df[(df['Hour'] >= 22) | (df['Hour'] <= 6)].sort_values(['hadm_id', 'charttime'])
#   print(f"Extract night time, %d smaples for %d trauma pacients"%(night_df_only_night.shape[0], night_df_only_night.hadm_id.nunique()))

#   # Unifying data group for over night date
#   # converting time at first_day_time_list(22:00 and 23:00)'s date to time at next_day_time_list's date
#   night_df.loc[:, 'Date_Group'] = night_df.Date
#   night_df.loc[night_df['Hour'].isin(np.arange(22-ffill_window_size, 24)), 'Date_Group'] = (night_df['Date'] + timedelta(days=1))
#   night_df.loc[night_df['Hour'].isin(np.arange(22-ffill_window_size, 24)), 'Day'] = (night_df['Day'] + 1)

#   # aggregate valus in the same hour into 1 value per feature
#   night_AggInHour_df = night_df[[
#       'hadm_id',# 'icustay_id',
#       'Date_Group', 'Day', 'Hour'] # id+ time
#       + features_list].groupby(['hadm_id', #'icustay_id',
#                                 'Date_Group', 'Day','Hour']).mean().reset_index()

#   # fill NaN values within each group (same patient & same night)
#   if filling_method=='forward':
#     # Forward Fill NA/NaN values by propagating the last valid observation to next valid
#     night_AggInHour_df = night_AggInHour_df.groupby(['hadm_id', 'Date_Group', 'Day']).apply(lambda group: group.ffill()).reset_index(drop=True)
#     # drop row that still contains nan values
#     night_AggInHour_df.dropna(subset= features_list, axis = 0, how = 'any', inplace = True)
#     print(f"After(ffil) drop na, %d samples for %d trauma patients"%(night_AggInHour_df.shape[0], night_AggInHour_df.hadm_id.nunique()))

#   # Filter for rows between 22:00 and 06:00 (drop the timestemp used to filling missing value)
#   night_AggInHour_df = night_AggInHour_df[(night_AggInHour_df['Hour'] >= 22) | (night_AggInHour_df['Hour'] <= 6)]

#   # convert time to index in the list. ex. 22:00 to index 0, 6:00 to index 8
#   night_time_list = [22, 23] + [i for i in range(7)]
#   night_AggInHour_df.loc[:, 'TimeIndex'] = night_AggInHour_df['Hour'].map( {night_time_list[i]: i for i in range(9)})
#   print(f"Finial night time data, %d samples for %d trauma patients"%(night_AggInHour_df.shape[0], night_AggInHour_df.hadm_id.nunique()))
#   return night_AggInHour_df
# #night_data = extract_night_data(raw_data, filling_method='forward', features_list=FEATURES_LIST)
# #night_data = extract_night_data(raw_data, filling_method=None, features_list=FEATURES_LIST)

"""
# Reshape
Convert 1D chart record To 2d time-series data with shape (T, F), where T=9 as 9 timestemps, F=6 as 6 features
"""

def gen_2Dnight_ti(df):
  """
  groups by patient and night, then aggregates the values into 2D arrays.
  each row represets one patienti on one night
  """
  index_columns = ['hadm_id', 'Date_Group', 'Day','Hour', 'TimeIndex']
  df = df.sort_values(index_columns)
  # Group by ids: patients and time & # Aggregate values into 2D arrays
  ti = df.groupby(['hadm_id', 'Date_Group','Day']).apply(lambda x: x.drop(columns=index_columns).values).reset_index()
  ti.columns = ['hadm_id', 'Date_Group', 'Day', 'Temporal Features']
  return ti
# night_ti = gen_2Dnight_ti(night_data)

"""
# Load or Generate vital signs Features
"""
def load_vs_features(night_ti_path,
                     preprocess_path, sepsis_preprocess_path, project_path, project_id,
                     features_list, TRUM_df, filling_method=None):
  # night_ti_path = os.path.join(ti_data_path, "vs_ti.pkl")
  if os.path.exists(night_ti_path):
      night_ti = pd.read_pickle(night_ti_path)
  else:
    trum_ids = TRUM_df[['subject_id',	'hadm_id',	'icustay_id']]
    # get admittime
    demog_df = spesis_label.Load_Trauma_Demographics(preprocess_path, sepsis_preprocess_path, project_path,
                                                    trum_ids[['hadm_id']].drop_duplicates())[['hadm_id', 'admittime', 'adm_date']]
    trum_ids = trum_ids.merge(demog_df, on='hadm_id')

    # Extract 6 features from MIMIC dataset
    raw_data = Extract_Trauma_Raw_VitalSigns(trum_ids, preprocess_path, project_id,
                                              features_list = features_list,
                                              isreport=True)

    # Extract night-time hours (22:00 to 06:00) & filling the missing value
    night_data = extract_night_data(raw_data, filling_method=filling_method, features_list=features_list)
    # Reshape the chart data into 2D time series data
    night_ti = gen_2Dnight_ti(night_data).reset_index(drop=True)
    # save
    night_ti.to_pickle(night_ti_path)
    print(f"Finial time-series data, %d samples for %d trauma patients"%(night_ti.shape[0], night_ti.hadm_id.nunique()))
  return night_ti

## Select Trauma Population (IDs)
#TRUM_df = trauma_cohort.trum_population_ids(
#    DATASET_PATH, PREPROCESS_DATA_PATH, #local path: mimiciii dataset
#    PROJECT_ID,                         #mimiciii dataset: bigquery id
#    vent_type=['MechVent'], vent_threshold=3,
#    is_report=True)
#TRUM_df.rename({"date_count":"MV_day_count"}, axis=1, inplace=True)
#trum_ids = TRUM_df[['subject_id',	'hadm_id',	'icustay_id']]
#
#night_ti = load_vs_features(os.path.join(TIDATA_PATH, 'vs_ti_ffil.pkl'),
#                            PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH, PROJECT_PATH,PROJECT_ID,
#                            FEATURES_LIST, TRUM_df, filling_method='forward')
#night_ti.shape
#night_ti = load_vs_features(os.path.join(TIDATA_PATH, 'vs_ti_w_nan.pkl'),
#                            PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH, PROJECT_PATH,PROJECT_ID,
#                            FEATURES_LIST, TRUM_df, filling_method=None)
#night_ti.shape

