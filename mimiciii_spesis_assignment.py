# -*- coding: utf-8 -*-
"""Spesis Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nz2aNiBbNHo2igA_O69kz6-qgO3loAcc

This script accesses the MIMIC database and extracts sub-tables for use in defining the final septic patient cohort in the [next step](https://colab.research.google.com/drive/1txkCiCsdXZ4wKlkV2yjePUq_nbuXjcVN?usp=chrome_ntp#scrollTo=LXoZFtcTGLYb&uniqifier=1).

sub-tables:
* trum_demog: Trauma Demographics (with truma population ids `trum_ids_df`)
* cx: Culture
* abx (Antibiotics administration)


**Resference**:

* This is a pure-python implementation based on a corrected version of the original R repo accompanying ["Defining Posttraumatic Sepsis for Population-Level Research"](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2800552) for MIMIC Dataset

* It is also sourced and modified from:
> [Microsoft mimic_sepsis](https://github.com/microsoft/mimic_sepsis/tree/main) \
> [MIMIC-III Concepts](https://github.com/MIT-LCP/mimic-code/tree/b9ed7a3d22a85dd95a50797e15bd24d566bce337/mimic-iii/concepts)


**Notes**:

This notebook assumes you have access to MIMIC III (v1.4) on Google BigQuery.
> - To get access for MIMIC III(v1.4) follow [link](https://physionet.org/content/mimiciii/1.4/)
> - To set up MIMIC data on Google BigQuery, follow [link](https://mimic.mit.edu/docs/gettingstarted/cloud/bigquery/)
> - To access MIMIC data in Google Colab, check the [link](https://colab.research.google.com/drive/1REu-ofzNzqsTT1cxLHIegPB0nGmwKaM0?usp=sharing#scrollTo=s-MoFA6NkkbZ)

# Set Up
"""

# Commented out IPython magic to ensure Python compatibility.
import gzip
import os
import re
import numpy as np
import pandas as pd
from datetime import datetime
from matplotlib import pyplot as plt

# cd to code folder
# %cd /content/drive/MyDrive/Yin_AutoEncoder/mimiciii_code/Project
import mimic_utils as utils
import mimiciii_icu_trauma_patient_cohort as trauma_cohort
import spesis_assignment_preprocess as spesis_preprocess

## Project Path
#PROJECT_PATH = '/content/drive/MyDrive/Yin_AutoEncoder/mimiciii_code/Project'
## Data Path
## mimic original dataset path
#DATASET_PATH = os.path.join(PROJECT_PATH, '1.4')
#PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess')
## SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#TIDATA_PATH = os.path.join(PROJECT_PATH, 'TiData')
#
## environment variables of BigQuery
#PROJECT_ID = 'sepsis-mimic3'  #this need to change according to your project_id in BigQuery

"""# 0. Load and Preprocess Tabels"""

############################## Trauma Demographics ###########################
# demog_df
#   This table(demog_df) should contain 1 row per patient with unique hadm_id
#   and corresponding info:
#       admittime, dischtime, hospital length of stay
###############################################################################
def Load_Trauma_Demographics(preprocess_path, sepsis_preprocess_path, project_id, trum_ids_df):
  # load
  trum_demog_path = os.path.join(sepsis_preprocess_path, "trum_demographics.csv")
  if os.path.exists(trum_demog_path):
      trum_demog = pd.read_csv(trum_demog_path, index_col=0)
  else:
      demog_path = os.path.join(preprocess_path, "demographics.csv")
      if os.path.exists(demog_path):
        demog_df = pd.read_csv(demog_path, index_col=0)
      else:
        demog_df = utils.demog_sql2df(project_id, saved_path=preprocess_path)
      # Extract on truma pacient info
      trum_demog = trum_ids_df.merge(demog_df[
          ['hadm_id', 'admittime',	'dischtime', 'los_hospital_hours', 'hospital_expire_flag']],
                                    on='hadm_id', how='left').drop_duplicates(['hadm_id'])
      trum_demog.to_csv(trum_demog_path)
  # trum_demog = trum_demog[['hadm_id', 'admittime',	'dischtime']]
  trum_demog['adm_datetime'] = pd.to_datetime(trum_demog.admittime)
  trum_demog['adm_date'] = pd.to_datetime(trum_demog.admittime).dt.date
  trum_demog['disch_date'] = pd.to_datetime(trum_demog.dischtime).dt.date
  print(f"Our cohort size is %d (hadm_id)\n"%trum_demog.hadm_id.nunique())
  return trum_demog

############################## Tissue Cultures ################################
# Blood Cultures that record at least 72 h after admission (data extracted from MicrobiologyEvents)
###############################################################################
def Load_Tissue_Cultures(sepsis_preprocess_path, project_id, trum_demog,
                         time_threshold=('cx_hour', 72)):
  # load
  culture_path = os.path.join(sepsis_preprocess_path, "trum_qualify_culture.csv")
  if os.path.exists(culture_path):
      cx_df = pd.read_csv(culture_path, index_col=0)
  else:
      cx_df = spesis_preprocess.culture_selection(project_id, trum_ids_df, is_report=True)
      cx_df.to_csv(culture_path)
  # at or after 72 hospital hours
  # Extract date & time
  cx_df['cx_date'] =  pd.to_datetime(cx_df['charttime']).dt.date
  cx_df['cx_datetime'] =  pd.to_datetime(cx_df['charttime'])#.dt.date
  cx_df = cx_df[['hadm_id','cx_date', 'cx_datetime', #'charttime'
                  'spec_itemid', 'spec_type_desc', 'linksto']
                    ].merge(trum_demog[['hadm_id', 'adm_datetime']], on='hadm_id', how='left')

  # SOLUTION2: Compute and fillter cx_time >= 72h & (drop duplicates)
  cx_df['cx_diff'] = (cx_df['cx_datetime'] - cx_df['adm_datetime'])#.dt.round("h")
  # cx_hour=i: the ith hosipital hour to order this cultures
  # cx_hour includes negative values, which represents the culture admit time is before hospital admission time
  cx_df['cx_hour'] = (cx_df['cx_datetime'] - cx_df['adm_datetime']).dt.round("h") // np.timedelta64(1, 'h')
  # cx_df = cx_df[cx_df.cx_hour >= 72].sort_values(['hadm_id','cx_datetime']).reset_index(drop=True)
  # (other option is to filter on or after 3 hosipital day)
  # cx_day=j: the jth day hosipital that order this cultures (floordiv cx_hour/24 )
  # cx_day = 0 means the culture admit time is 12h before hospital admission time
  cx_df['cx_day'] = (cx_df['cx_date'] - cx_df['adm_datetime'].dt.date).apply(lambda x: x.days) + 1 # sol_1: date difference +1
  # cx_day_round=k: the k th day hosipital that order this cultures (round cx_hour to Day)
  # cx_df['cx_day_round'] = (cx_df['cx_datetime'] - cx_df['adm_datetime']).dt.round("d").apply(lambda x: x.days) + 1 # sol_2: difference based on timestemp(Date+time) and then round to day
  # cx_df = cx_df[cx_df.cx_day >= 3].sort_values(['hadm_id','cx_datetime']).reset_index(drop=True) #filter on or after 3 day

  # filter out first few days recordes
  unit, threshold = time_threshold
  cx_df = cx_df[cx_df[unit] >= threshold].sort_values(['hadm_id','cx_datetime']).reset_index(drop=True)

  # only MicrobiologyEvents
  cx_df = cx_df[cx_df.linksto=='MicrobiologyEvents']

  # only BLOOD CULTURE
  cx_df = cx_df[cx_df.spec_itemid.isin([70012,
                                        # 70011, 70013, 70087
                                        ])]
  print(f'%d culture recordes for %d patients'%(cx_df.shape[0], cx_df.hadm_id.nunique()))
  return cx_df


############################### Antibiotics ##################################
# Antibiotics: an order for a new intravenous or qualifying oral antibiotic,
#   1. Load Qualifying Antibiotic: (load from 'trum_qualify_antibiotics.csv')
    # Include: all IV and certain Qualifying PO antibiotics
    # Exclude: all 3 antibiotics used for surgical prophylaxis,
#   2. Clean Up:
    # drug name format
    # time period
#   3. Label NEW Antibiotic:
    # not administered within the previous 48 hours/ previous day
#   4. Exclude first day antibiotics:
    # For the antibiotic that started on “day 1”
    # Exclude the entire antibiotic record.
#   5. Check Continued Administered Antibiotic
    # antibiotic administered for at least 4 consecutive days or until death or until discharge
    # i.e. 4 consecutive days of any qualifying antibiotic (does not have to be the same antibiotic).
###############################################################################
def assign_abx_seq(df):
  newAbx_index = df[df.newAbx==1].index
  n=newAbx_index.size
  for seq, row_ind in enumerate(newAbx_index,1):
    if (seq)==n:
      df.loc[row_ind:df.index[-1],'Abx_seq'] = seq
    else:
      df.loc[row_ind:newAbx_index[seq], 'Abx_seq'] = seq
    # print(seq, row_ind)
  return df

def continued_adm_abx(group):
  # 5. Check Continued Administered Antibiotic
  # antibiotic administered for at least 4 days or until death or until discharge
  date_df_all = group.apply(lambda row: pd.Series(pd.date_range(row['startdate'], row['enddate'])),axis=1)
  # init return table
  df = pd.DataFrame(columns=group.columns.values)
  for (index, row), AtLeast4Days_isna in zip(group.iterrows(), group.AtLeast4Days.isna()):
    if AtLeast4Days_isna:
      qualify_df = group[group.startdate>= row.startdate]#.index

      if qualify_df.shape[0] == 1: # not change to another abx
        row.AtLeast4Days = 0
      else:
        date_df = date_df_all[date_df_all.index.isin(qualify_df.index)].stack().sort_values().drop_duplicates().reset_index(drop=True).to_frame()#.reset_index()
        date_df.columns = ['date']
        date_df['date'] = date_df.date.dt.date
        date_df_shape = date_df.shape[0]

        # check if have a continued administered until death or until discharge
        if date_df_shape < 4: # out of index
          is_discharge_on_last_day = date_df.iloc[-1].date >= row.disch_date
          if is_discharge_on_last_day:
            if date_df_shape == 1: #just one ?
              row.AtLeast4Days = 1
            elif (date_df.iloc[-1].date - date_df.iloc[0].date) == pd.Timedelta(days=(date_df_shape-1)):
                row.AtLeast4Days = 1
            else:
              row.AtLeast4Days = 0
          else:
            row.AtLeast4Days = 0
        elif (date_df.iloc[3].date) == (row.startdate + pd.Timedelta(days=3)) : # check if continued for 4 day
          row.AtLeast4Days = 1
        else:
          row.AtLeast4Days = 0
    df = pd.concat([df, row.to_frame().transpose()],axis=0)
  return df

def Load_Antibiotics(sepsis_preprocess_path,
                     dataset_path, project_id,
                     trum_ids_df, trum_demog,
                     day_threshold=1):
  # 1.Load
  abx_path = os.path.join(sepsis_preprocess_path, "trum_qualify_antibiotics.csv")
  if os.path.exists(abx_path):
      abx_df = pd.read_csv(abx_path, index_col=0)
  else:
      abx_df = spesis_preprocess.antibiotics_selection(dataset_path, project_id, trum_ids_df)
      abx_df.to_csv(abx_path)
  # extract date
  abx_df['startdate'] =  pd.to_datetime(abx_df['startdate']).dt.date
  abx_df['enddate'] =  pd.to_datetime(abx_df['enddate']).dt.date
  abx_df['enddate'].fillna(abx_df['startdate'], inplace=True)
  abx_df = abx_df.drop_duplicates(['hadm_id', 'startdate', 'enddate', 'drug'])
  num_qualifying_antibiotic = abx_df.shape[0]
  print("#of qualifying antibiotic", num_qualifying_antibiotic)
  # Exclude: all 3 antibiotics used for surgical prophylaxis,
  # specifically, ampicillin-sulbactam and erythromycin
  abx_df = abx_df[abx_df.isProphylactic==0]
  pa_count = num_qualifying_antibiotic-abx_df.shape[0]
  print(f"Exclude %d prophylaxis antibiotics (ampicillin-sulbactam and erythromycin)"%(pa_count))

  # 2. Clean up records: drug name format & time period
  # time period
  # Drop enddate that earlier than startdate
  before_drop_noise = abx_df.shape[0]
  noise_data = abx_df.startdate > abx_df.enddate
  clean_abx_df = abx_df[~noise_data]
  print(f"Drop %d noise abx records s.t. startdate>enddate"%(before_drop_noise-clean_abx_df.shape[0]))
  # drug name format
  clean_abx_df['drug'] = clean_abx_df.drug.apply(str.lower)
  clean_abx_df.drug.replace({
      'ciprofloxacin iv': 'ciprofloxacin',
      'clindamycin phosphate': 'clindamycin',
      'erythromycin lactobionate': 'erythromycin',
      'gentamicin sulfate': 'gentamicin',
      'metronidazole (flagyl)': 'metronidazole',
      'piperacillin-tazobactam na': 'piperacillin-tazobactam',
      'sulfameth/trimethoprim': 'sulfamethoxazole-trimethoprim',
      'vancomycin enema': 'vancomycin',
      'vancomycin hcl': 'vancomycin',
      'vancomycin oral liquid': 'vancomycin'
      }, inplace=True)

  # 3. assign newAbx
  new_abx_df = clean_abx_df.sort_values(['hadm_id', 'drug','startdate',	'enddate'])
  new_abx_df['newAbx'] = np.nan #init
  new_abx_df.iloc[0,-1] = 1 # assign newAbx label for first row
  prev_df = new_abx_df.shift(periods=1)
  prev_df.iloc[0] = new_abx_df.iloc[0]
  new_abx_df.loc[new_abx_df.hadm_id != prev_df.hadm_id, 'newAbx'] = 1 # new pacient
  new_abx_df.loc[new_abx_df.drug !=prev_df.drug, 'newAbx'] = 1 # new pacient
  diff_day =(new_abx_df.startdate - prev_df.enddate).apply(lambda x: x.days)
  new_abx_df.loc[diff_day>1, 'newAbx'] = 1 #not administered within the previous 48 hours/ on previous day
  new_abx_df = new_abx_df.groupby('hadm_id').apply(assign_abx_seq).reset_index(drop=True)
  new_abx_df = new_abx_df.groupby(['hadm_id', 'Abx_seq']).agg({
      'startdate': "min",
      'enddate': "max",
      'drug': lambda x: x.iloc[0],
      'isProphylactic': lambda x: x.iloc[0]}).reset_index()

  # 4.Drop the first few day(s) abx (by default: abx day >= 1)
  new_abx_df = trum_demog[['hadm_id','adm_date','disch_date']].merge(new_abx_df, on='hadm_id', how='right')
  # Compute anti_day
  # anti_day=i: the ith  hosipital day that take this antibiotics
  new_abx_df['abx_day'] = (new_abx_df['startdate'] - new_abx_df['adm_date']).apply(lambda x: x.days) + 1
  # fillter out abx started as 1st day
  new_abx_df = new_abx_df[new_abx_df.abx_day >= day_threshold]
  new_abx_df['abx_day'] = new_abx_df.abx_day.astype(int)

  # 5. Check Continued Administered Antibiotic
  # antibiotic administered for at least 4 days or until death or until discharge
  diff_day = (new_abx_df.enddate - new_abx_df.startdate).apply(lambda x: x.days) + 1
  # check per drug record
  new_abx_df.loc[diff_day >= 4, 'AtLeast4Days'] = 1 # at leat 4 days
  new_abx_df.loc[new_abx_df.enddate >= new_abx_df.disch_date, 'AtLeast4Days'] = 1 # until discharge
  # check all the drugs' record since the current dug day
  new_abx_df = new_abx_df.groupby(['hadm_id']).apply(continued_adm_abx).reset_index(drop=True)
  # Sort and reset index(index from 1 instead of 0)
  new_abx_df = new_abx_df.sort_values(['hadm_id','startdate']).reset_index(drop=True)
  new_abx_df.index += 1

  abx_path = os.path.join(sepsis_preprocess_path, "trum_NewAbx.csv")
  new_abx_df.to_csv(abx_path)
  return new_abx_df

################################# SOFA score ####################################
#  SOFA score:
#    a modified version of the SOFA score that omits the Glasgow Comma Scale (GCS) and Urine Output(UO)
#    generate a row for every hour for all trauma patient was in the ICU
#################################################################################
def Load_Sofa(sepsis_preprocess_path, project_id, preprocess_path,
              trum_ids_df,trum_demog):
  sofa_path = os.path.join(sepsis_preprocess_path, "trum_sofa.csv")
  if os.path.exists(sofa_path):
      sofa_df = pd.read_csv(sofa_path, index_col=0)
  else:
      sofa_df = spesis_preprocess.SOFA_calculate_selection(project_id, trum_ids_df, preprocess_path, sepsis_preprocess_path)
      sofa_df.to_csv(sofa_path)
  sofa_df
  # Compute sofa_day (drop duplicates)
  # sofa_day=i: the ith day hosipital day that order this sofa score
  sofa_df['sofa_date'] =  pd.to_datetime(sofa_df['starttime']).dt.date
  sofa_df = sofa_df.merge(trum_demog[['hadm_id', 'adm_date']], on='hadm_id', how='left')
  sofa_df['sofa_day'] = (sofa_df['sofa_date'] - sofa_df['adm_date']).apply(lambda x: x.days) + 1
  return sofa_df

def compute_sofa_increase_in7days(day, sofa):
    """
    given
      an integer 'day': used to calculate the window which is a full 7 days (3 days before, day of, 3 days after)
      a 'sofa' dataframe: which includes all sofa score for a pacient(only includes 1 hadm_id)
    return
      if SOFA increase by at least 2 points within 7 days window
        then [1, sofa_earlier_hr, sofa_later_hr]
        # only show fist pair that sofa at later_hr - sofa at earlier_hr >= 2
      else
        [0, np.nan, np.nan]
    """
    sofa_7day_windown_df = sofa[sofa.sofa_day.between(day-3, day+3, inclusive='both')].reset_index().rename({'index':'sofa_index'}, axis=1)
    sofa_7day_windown_values = sofa_7day_windown_df.sofa_24hours.values

    diff = np.subtract.outer(sofa_7day_windown_values, sofa_7day_windown_values)
    increase = np.tril(diff,-1) # only keep the Ti-Tj, s.t i>j
    later_time, earlier_time = (increase>1).nonzero()

    if later_time.size == 0:
      is_sofa_inc_atlease2 = 0
      later_index, earlier_index = np.nan, np.nan
    else:
      is_sofa_inc_atlease2 = 1
      # only first pair
      later_index = sofa_7day_windown_df.iloc[later_time[0]].sofa_index
      earlier_index = sofa_7day_windown_df.iloc[earlier_time[0]].sofa_index
    return np.array([is_sofa_inc_atlease2, earlier_index, later_index])

################### Criteria for assigning sepsis ###############################

# 1. Culture-Antibiotic Criteria(infection)
#   New antibiotic within **48hrs before or after** a tissue culture
#   (New Antibiotic: antibiotic was not given within prior day)
#   ##(option) to use "whichever comes first" rule for sepsis onset
#   ##i.e., new IV antibiotic timestamp instead of culture timestamp when new IV antibiotic is started before the culture
# 3. Organ Dysfunction 
#   SOFA increase by at least 2 points within 7-day window 3 days before or 3 days after culture

#################################################################################
def sepsis_algorithm(cx_df, new_abx_df, sofa_df,
                     sepsis_preprocess_path):
  # drop drop_duplicates date
  # cx_df have sorted and reindexed, so we will keep the earliest cx_datetime for each date
  cx_date_df = cx_df[['hadm_id', 'cx_date', 'cx_datetime', 'spec_type_desc', 'cx_day']].drop_duplicates(['hadm_id', 'cx_day' ])
  # cx_df have sorted and reindexed
  abx_date_df = new_abx_df[['hadm_id', 'drug',
                'abx_day', 'startdate', 'enddate',
                'AtLeast4Days', 'isProphylactic']]
  # New qulify antibiotic administered for at least 4 days or until death or until discharge
  abx_date_df = abx_date_df[
      # (abx_date_df.newAbx==1) &
      (abx_date_df.AtLeast4Days==1)].drop_duplicates(['hadm_id', 'abx_day'])


  # Init Sepsis Table 'sepsis_candidate_df' include:
  # culture info: cx timestemp & index of cx_df(or cx_date_df should share same index)
  # antibiotic info: abx timestemp & index of clean_abx_df(or abx_date_df should share same index)
  sepsis_candidate_rows = []
  sofa_rows = []
  # for each patients
  for hadm_id in cx_date_df.hadm_id.unique():
    # get culture
    cx = cx_date_df[cx_date_df.hadm_id==hadm_id]
    cx_date = cx.cx_day.values
    # get antibiotic
    abx = abx_date_df[abx_date_df.hadm_id==hadm_id]
    abx_date = abx.abx_day.values
    # get sofa score
    sofa = sofa_df[sofa_df.hadm_id==hadm_id]#.reset_index()
    # init sepsis onset candidates (based on cx)
    candidate_df = cx.reset_index().rename({'index':"cx_index"},axis=1)[['hadm_id', 'cx_index', 'cx_datetime','cx_day']]

    # 1.(Version1) Keep only cultures that met 48hr-48hr (2d-2d) new abx criteria
    # # compute pairwise differences
    differences = np.abs(np.subtract.outer(cx_date, abx_date)) #with shape (#of cx, #of abx)
    # check which abx met 2d-2d criteria
    in_5DayWindow = np.where(differences<=2, 1, 0)
    # print(in_5DayWindow)
    # # 1.(Version2)Keep only cultures that met 24hr-72hr (1d-3d) new abx criteria
    # # compute pairwise differences: check if (abx-cx) in range [-1, 3]
    # differences = np.subtract.outer(abx_date, cx_date).transpose() #with shape (#of cx, #of abx)
    # in_5DayWindow = (differences >= -1) & (differences <= 3)
    # in_5DayWindow = np.where(in_5DayWindow, 1, 0)
    # # print(in_5DayWindow)

    # save the qualify abx info for each culture
    candidate_df['num_abx'] = np.sum(in_5DayWindow,axis=1) # num of qulify abx
    candidate_df['abx_index_li'] = [in_5DayWindow[i]*abx.index.values for i in range(candidate_df.shape[0])] #save abx index that met criteria
    candidate_df['abx_index_li'] = candidate_df.abx_index_li.apply(lambda x: x[x!=0]) # drop 0 (since abx_df start index on 1,
                                                                                      #         so 0 means abx in that position is not met criteria)
    # only keep the cultures that met culture-antibiotic criteria(infection)
    candidate_df = candidate_df[candidate_df.num_abx>0]
    candidate_df['isInfection'] = 1
    # use earliest abx info for each culture
    candidate_df['first_abx_date'] = candidate_df.abx_index_li.apply(lambda x: abx.loc[x[0],'startdate'])
    candidate_df['first_abx_day'] = candidate_df.abx_index_li.apply(lambda x: abx.loc[x[0],'abx_day'])
    candidate_df['isProphylactic_first'] = candidate_df.abx_index_li.apply(lambda x: abx.loc[x[0],'isProphylactic'])
    # candidate_df.loc[candidate_df.num_abx!=0, 'first_abx_date'] = candidate_df.loc[candidate_df.num_abx!=0, 'abx_index_li'].apply(lambda x: abx.loc[x[0],'startdate'])
    # candidate_df.loc[candidate_df.num_abx!=0, 'isProphylactic_first'] = candidate_df.loc[candidate_df.num_bx!=0, 'abx_index_li'].apply(lambda x: abx.loc[x[0],'isProphylactic'])
    # get the earliest timepoint meeting culture-antibiotic criteria as onset time
    candidate_df['timestemp'] = np.where(candidate_df.cx_day > candidate_df.first_abx_day,
                                         pd.to_datetime(candidate_df.first_abx_date),
                                         candidate_df.cx_datetime)
    candidate_df['day'] = np.where(candidate_df.cx_day > candidate_df.first_abx_day,
                                   candidate_df.first_abx_day,
                                   candidate_df.cx_day)
    # # Use culture timestemp as onset time
    # candidate_df['timestemp'] = candidate_df.cx_datetime
    # candidate_df['day'] = candidate_df.cx_day

    # print(candidate_df.columns)
    candidate_df = candidate_df[['hadm_id', 'timestemp', 'day',            # for each patient, candidate info
                                'cx_index', 'cx_day', 'cx_datetime',                    # culture info
                                'isInfection', 'num_abx','abx_index_li', # infection & corresponding qualify abx
                                'first_abx_day', 'isProphylactic_first', # the earliest abx
                                ]]


    # 2.check Organ Dysfunction: SOFA increase by at least 2 points within 7-day window (3 days before or 3 days after culture)
    if candidate_df.shape[0] != 0: #only calcuate this when candidate_df is not empty
      # isSepsis: organ dysfunction: required sofa incresing by 2
      candidate_df[['isSepsis', 'sofa_index_1', 'sofa_index_2']] = np.stack(candidate_df.day.apply(lambda x: compute_sofa_increase_in7days(x, sofa)))
      # display(  np.stack(candidate_df.day.apply(lambda x: compute_sofa_increase_in7days(x, sofa))))
      # display(candidate_df)
      # accumulate table that met the sofa criteria
      # sepsis_candidate_rows.append(candidate_df[candidate_df.isSepsis==1])
      sepsis_candidate_rows.append(candidate_df) #accumulate table even if not met the sofa criteria

    # show details
    # print('hadm_id', hadm_id)
    # display(cx)
    # display(abx)
    if candidate_df.shape[0] != 0:
      hr_arr = np.unique(candidate_df[['sofa_index_1', 'sofa_index_2']].values.flatten())
      hr_arr = hr_arr[~np.isnan(hr_arr)].tolist()
      sofa_rows.append(sofa.loc[hr_arr,:])
      # display(sofa.loc[hr_arr,:])
    # display(candidate_df)
    # break

  sepsis_candidate_df = pd.concat(sepsis_candidate_rows, axis=0)
  selected_sofa_df = pd.concat(sofa_rows, axis=0)

  # save
  cx_date_df.to_excel(os.path.join(sepsis_preprocess_path, "cx_final.xlsx"))
  abx_date_df.to_excel(os.path.join(sepsis_preprocess_path, "abx_final.xlsx"))
  selected_sofa_df.to_excel(os.path.join(sepsis_preprocess_path, "selected_sofa_final.xlsx"))
  sepsis_candidate_df.to_excel(os.path.join(sepsis_preprocess_path, "sepsis_final.xlsx"))

  return sepsis_candidate_df

def gen_label_perHadm_id(trum_ids_df, sepsis_candidate_df, is_report=False):
  # get onset day for sepsis sample
  sepsis_candidate_df = sepsis_candidate_df[['hadm_id',
                                             'timestemp', 'day',      # the earlier timestemp between (cx & abx)
                                             'cx_day', 'cx_datetime', # culture time to locate infection
                                             'first_abx_day',         # antibiotic time to locate infection
                                             'isInfection','isSepsis']]
  is_infection_ids = sepsis_candidate_df.hadm_id.unique()
  sepsis_positive_df = sepsis_candidate_df[sepsis_candidate_df.isSepsis==1].sort_values(['hadm_id', 'timestemp']).groupby('hadm_id').head(1)  # one raw per patient
  # sepsis_positive_df['label'] = 1

  # merge with all trauma cohort
  trauma_sepsis_label_df = trum_ids_df.merge(sepsis_positive_df, on='hadm_id', how='left')
  trauma_sepsis_label_df.loc[trauma_sepsis_label_df.hadm_id.isin(is_infection_ids), 'isInfection'] = 1
  trauma_sepsis_label_df.isInfection.fillna(0, inplace=True)
  trauma_sepsis_label_df.isSepsis.fillna(0, inplace=True)

  print('num of trauma:', trauma_sepsis_label_df.hadm_id.nunique())
  print('num of infection:', trauma_sepsis_label_df.isInfection.sum())
  print('num of sepsis:', trauma_sepsis_label_df.isSepsis.sum())
  return trauma_sepsis_label_df

"""
# Main
"""
def load_sepsis_label(sepsis_label_path,
                     preprocess_path, sepsis_preprocess_path, dataset_path, project_id,
                     trum_hadm_id_df):
  """
    Return a table s.t.each row represents a patitent. 
      if is non-sepsis patient, then isSepsis = 0.
      if is sepsis patient, then isSepsis = 1, with corresponding onset timestemp information.
  """
  if os.path.exists(sepsis_label_path):
      sepsis_label_df = pd.read_csv(sepsis_label_path, index_col=0)
  else:
    # Load & Preprocess
    trum_demog = Load_Trauma_Demographics(preprocess_path, sepsis_preprocess_path, project_id, trum_hadm_id_df)
    cx_df = Load_Tissue_Cultures(sepsis_preprocess_path, project_id, trum_demog, time_threshold=('cx_hour', 72))
    # display(cx_df.cx_hour.describe())
    new_abx_df = Load_Antibiotics(sepsis_preprocess_path, dataset_path, project_id, trum_hadm_id_df, trum_demog, day_threshold=1)
    sofa_df = Load_Sofa(sepsis_preprocess_path, project_id, preprocess_path, trum_hadm_id_df,trum_demog)
    # print(trum_demog.hadm_id.nunique(), sofa_df.hadm_id.nunique())

    # Criteria for Assigning Sepsis
    sepsis_candidate_df = sepsis_algorithm(cx_df, new_abx_df, sofa_df, sepsis_preprocess_path)
    # for all trauma patients, all
    trauma_sepsis_label_df = gen_label_perHadm_id(trum_hadm_id_df, sepsis_candidate_df)
    sepsis_label_df = trauma_sepsis_label_df[['hadm_id', 'isSepsis',
                                              'timestemp', 'day',      # min ( cx_timestemp, abx_timestemp)
                                              'cx_datetime', 'cx_day'
                                              ]]
    # sepsis_label_df = sepsis_label_df.merge(trum_demog[['hadm_id', 'admittime']], on='hadm_id')
    sepsis_label_df.to_csv(sepsis_label_path)
  return sepsis_label_df

## Select Trauma Population (IDs)
#SEPSIS_PREPROCESS_DATA_PATH = os.path.join(PROJECT_PATH, 'preprocess', 'sepsis_preprocess')
#TRUM_df = trauma_cohort.trum_population_ids(
#    DATASET_PATH, PREPROCESS_DATA_PATH, #local path: mimiciii dataset
#    PROJECT_ID,                         #mimiciii dataset: bigquery id
#    vent_type=['MechVent'], vent_threshold=3,
#    is_report=True)
#TRUM_df.rename({"date_count":"MV_day_count"}, axis=1, inplace=3)
##This table should contain 1 row per patient (with unique hadm_id)
#trum_ids_df = TRUM_df[['hadm_id']].drop_duplicates() # we only need Hosipital Admission ID
#
# TIDATA_PATH = os.path.join(PROJECT_PATH, 'TiData')
# sepsis_label_path = os.path.join(TIDATA_PATH, 'sepsis_label.csv')
# load_sepsis_label(sepsis_label_path,
#                   PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH, DATASET_PATH, PROJECT_ID,
#                   trum_hadm_id_df)

## Load & Preprocess
#trum_demog = Load_Trauma_Demographics(PREPROCESS_DATA_PATH, SEPSIS_PREPROCESS_DATA_PATH, PROJECT_ID,trum_ids_df)
#cx_df = Load_Tissue_Cultures(SEPSIS_PREPROCESS_DATA_PATH, PROJECT_ID, trum_demog, time_threshold=('cx_hour', 72))
## display(cx_df.cx_hour.describe())
#new_abx_df = Load_Antibiotics(SEPSIS_PREPROCESS_DATA_PATH, DATASET_PATH, PROJECT_ID, trum_ids_df, trum_demog, day_threshold=1)
#sofa_df = Load_Sofa(SEPSIS_PREPROCESS_DATA_PATH, PROJECT_ID, PREPROCESS_DATA_PATH, trum_ids_df, trum_demog)
## print(trum_demog.hadm_id.nunique(), sofa_df.hadm_id.nunique())
#
## Criteria for Assigning Sepsis
#sepsis_candidate_df = sepsis_algorithm(cx_df, new_abx_df, sofa_df, SEPSIS_PREPROCESS_DATA_PATH)
## for all trauma patients, all
#trauma_sepsis_label_df = gen_label_perHadm_id(trum_ids_df, sepsis_candidate_df)
#
#trauma_sepsis_label_df[['hadm_id', 'isSepsis',
#                        'timestemp', 'day',
#                        'cx_datetime', 'cx_day']].to_csv(os.path.join(TIDATA_PATH, 'sepsis_label.csv'))

"""
# Report
"""
## merge with truma demographic
#TRUM_df_hadm = TRUM_df.drop_duplicates('hadm_id')
#demog = pd.read_csv(os.path.join(PREPROCESS_DATA_PATH, "demographics.csv"), index_col=0)
#trauma_cohort_df = TRUM_df_hadm[['hadm_id', 'MV_day_count']].merge(demog[
#    ['hadm_id', 'hospital_expire_flag','los_hospital_hours', 'los_icu_hours']],
#                                                              on='hadm_id', how='left').drop_duplicates('hadm_id')
#trauma_cohort_df.MV_day_count.fillna(0, inplace=True)
#trauma_cohort_df = trauma_cohort_df.merge(trauma_sepsis_label_df, on='hadm_id')
## trauma_cohort_df
#
#display(trauma_sepsis_label_df[['cx_day', 'first_abx_day', 'day']].describe())
#
## sepsis day distribution
#display(trauma_sepsis_label_df.day.describe())
#trauma_cohort_df[['cx_day', 'first_abx_day', 'day']].plot(
#    kind = 'hist',
#    bins=np.arange(0,50),
#    subplots =True, layout=(3,1), figsize=(9,5),
#    xticks=np.arange(0, 50, 5)
#    )
#
#report_df = trauma_cohort_df.groupby('isSepsis').agg({
#    'hadm_id':'count',
#    'hospital_expire_flag':'sum',
#    'los_hospital_hours':'median',
#    'los_icu_hours': 'median',
#    'MV_day_count':'median'
#})
#report_df = report_df.rename({'hadm_id':'total_num',
#                              'hospital_expire_flag':'mortality_rate',
#                              'los_hospital_hours':'los_hospital_day_median',
#                              'los_icu_hours':'los_icu_day_median',
#                              'MV_day_count':'MV_day_median',},axis=1)
#report_df['sepsis_rate'] = report_df.total_num / trauma_cohort_df.shape[0]
#report_df['mortality_rate'] = report_df.mortality_rate /report_df.total_num
#report_df['los_hospital_day_median'] = report_df['los_hospital_day_median']// 24
#report_df['los_icu_day_median'] = report_df['los_icu_day_median']// 24
#report_df.rename({0: 'non-sepsis', 1:'sepsis'}, axis=0, inplace=True)

